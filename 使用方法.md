[Ultralytics YOLOv5 - Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/yolov5/)

# æ•°æ®é›†

> å…ˆè¦æŠŠæ•°æ®é›†æ”¾å…¥datasetä¸­ï¼Œä¿®æ”¹data/ç›®å½•ä¸‹çš„yamlï¼Œè°ƒæ•´ä¸ºè‡ªå·±çš„æ•°æ®é›†ï¼Œéœ€è¦è°ƒæ•´è·¯å¾„ï¼Œåˆ†ç±»æ•°ï¼Œæ ‡ç­¾å

> yoloæ•°æ®é›†æ ¼å¼(yolov5/v8çš„coco128å’Œéœ¹é›³å§å•¦Wzçš„yolo3ä¸ºä¾‹)
>
> txtå†…å®¹ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ `3 0.933536 0.486124 0.030408 0.154487`
>
> æ˜¯ label ä¸­å¿ƒæ¨ªåæ ‡ä¸å›¾åƒå®½åº¦æ¯”å€¼ ä¸­å¿ƒçºµåæ ‡ä¸å›¾åƒé«˜åº¦æ¯”å€¼ bboxå®½åº¦ä¸å›¾åƒå®½åº¦æ¯”å€¼ bboxé«˜åº¦ä¸å›¾åƒå®½é«˜æ¯”å€¼

```sh
#-------------------------------------------#
# 	yolov5 v8çš„æ ¼å¼
#	yaml:
#		path: ../datasets/coco128   # dataset root dir
#		train: images/train2017     # train images (relative to 'path') 128 images
#		val: images/train2017       # val images (relative to 'path') 128 images
#		test:                       # test images (optional)	
#-------------------------------------------#
datasets
â”œâ”€â”€ coco128
	â”œâ”€â”€ images
	â”‚	â”œâ”€â”€ train2017	# è®­ç»ƒå›¾ç‰‡
	â”‚	â””â”€â”€ val2017		# éªŒè¯å›¾ç‰‡
	â””â”€â”€ labels
    	â”œâ”€â”€ train2017	# è®­ç»ƒæ ‡ç­¾txt
    	â””â”€â”€ val2017		# éªŒè¯æ ‡ç­¾txt

#-------------------------------------------#
# 	yolov5 v8å¦çš„ä¸€ç§å›¾ç‰‡ç›®å½•æ ¼å¼
#	yaml:
#		path: ../datasets/coco128   # dataset root dir
#		train: train/images         # train images (relative to 'path')
#		val: val/images             # val images (relative to 'path')
#		test: test/images           # test images (optional)
#-------------------------------------------#
datasets
â”œâ”€â”€ coco128
	â”œâ”€â”€ train
	â”‚	â”œâ”€â”€ images  # è®­ç»ƒå›¾ç‰‡
	â”‚	â””â”€â”€ labels  # è®­ç»ƒæ ‡ç­¾txt
	â”œâ”€â”€ val
	â”‚	â”œâ”€â”€ images  # éªŒè¯å›¾ç‰‡
	â”‚	â””â”€â”€ labels  # éªŒè¯æ ‡ç­¾txt
	â””â”€â”€ test
	 	â”œâ”€â”€ images  # æµ‹è¯•å›¾ç‰‡
	 	â””â”€â”€ labels  # æµ‹è¯•æ ‡ç­¾txt


#-------------------------------------------#
#	éœ¹é›³å§å•¦Wzçš„yolo3
#-------------------------------------------#
data
â”œâ”€â”€ pascal_voc_classes.json		å­˜æ”¾ç±»åˆ«ä¿¡æ¯ {"aeroplane": 1, "bicycle": 2, "bird": 3, "boat": 4, "bottle": 5}
â”œâ”€â”€ train
â”‚	â”œâ”€â”€ images		# è®­ç»ƒå›¾ç‰‡
â”‚	â””â”€â”€ labels		# è®­ç»ƒæ ‡ç­¾txt
â””â”€â”€ val
	â”œâ”€â”€ images		# éªŒè¯å›¾ç‰‡
	â””â”€â”€ labels		# éªŒè¯å›¾ç‰‡txt
```

> `data/class20.yaml`

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# â”œâ”€â”€ yolov5
# â””â”€â”€ datasets
#     â””â”€â”€ yourname
#         â””â”€â”€ images/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒå›¾ç‰‡
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯å›¾ç‰‡
#         â””â”€â”€ labels/
#             â””â”€â”€ train2017/  å­˜æ”¾è®­ç»ƒæ ‡ç­¾  class x_center y_center width height
#             â””â”€â”€ val2017/    å­˜æ”¾éªŒè¯æ ‡ç­¾


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/classes20  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/val2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
names:
  0: aeroplane
  1: bicycle
  2: bird
  3: boat
  4: bottle
  5: bus
  6: car
  7: cat
  8: chair
  9: cow
  10: diningtable
  11: dog
  12: horse
  13: motorbike
  14: person
  15: pottedplant
  16: sheep
  17: sofa
  18: train
  19: tvmonitor
```

# æ¨¡å‹

# ä¸‹è½½æƒé‡

> å°†ä¸‹è½½å¥½çš„æƒé‡æ”¾åˆ°`weights/`æ–‡ä»¶ä¸‹ä¸‹

### é¢„è®­ç»ƒæ¨¡å‹

| æ¨¡å‹                                                         | å°ºå¯¸ ï¼ˆåƒç´ ï¼‰ | mAPval 50-95  | mAPval 50     | æ¨ç†é€Ÿåº¦ CPU b1 ï¼ˆmsï¼‰ | æ¨ç†é€Ÿåº¦ V100 b1 ï¼ˆmsï¼‰ | é€Ÿåº¦ V100 b32 ï¼ˆmsï¼‰ | å‚æ•°é‡ (M) | FLOPs @640 (B) |
| ------------------------------------------------------------ | ------------- | ------------- | ------------- | ---------------------- | ----------------------- | -------------------- | ---------- | -------------- |
| [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt) | 640           | 28.0          | 45.7          | **45**                 | **6.3**                 | **0.6**              | **1.9**    | **4.5**        |
| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt) | 640           | 37.4          | 56.8          | 98                     | 6.4                     | 0.9                  | 7.2        | 16.5           |
| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt) | 640           | 45.4          | 64.1          | 224                    | 8.2                     | 1.7                  | 21.2       | 49.0           |
| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt) | 640           | 49.0          | 67.3          | 430                    | 10.1                    | 2.7                  | 46.5       | 109.1          |
| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt) | 640           | 50.7          | 68.9          | 766                    | 12.1                    | 4.8                  | 86.7       | 205.7          |
|                                                              |               |               |               |                        |                         |                      |            |                |
| [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n6.pt) | 1280          | 36.0          | 54.4          | 153                    | 8.1                     | 2.1                  | 3.2        | 4.6            |
| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s6.pt) | 1280          | 44.8          | 63.7          | 385                    | 8.2                     | 3.6                  | 12.6       | 16.8           |
| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m6.pt) | 1280          | 51.3          | 69.3          | 887                    | 11.1                    | 6.8                  | 35.7       | 50.0           |
| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt) | 1280          | 53.7          | 71.3          | 1784                   | 15.8                    | 10.5                 | 76.8       | 111.4          |
| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x6.pt) +[TTA](https://github.com/ultralytics/yolov5/issues/303) | 1280 1536     | 55.0 **55.8** | 72.7 **72.7** | 3136 -                 | 26.2 -                  | 19.4 -               | 140.7 -    | 209.8 -        |

ç¬”è®°

- æ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œè®­ç»ƒ 300 epochsã€‚nå’Œsæ¨¡å‹ä½¿ç”¨ [hyp.scratch-low.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml) ï¼Œå…¶ä»–æ¨¡å‹éƒ½ä½¿ç”¨ [hyp.scratch-high.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-high.yaml) ã€‚
- **mAPval**åœ¨å•æ¨¡å‹å•å°ºåº¦ä¸Šè®¡ç®—ï¼Œæ•°æ®é›†ä½¿ç”¨ [COCO val2017](http://cocodataset.org/) ã€‚
  å¤ç°å‘½ä»¤ `python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`
- **æ¨ç†é€Ÿåº¦**åœ¨ COCO val å›¾åƒæ€»ä½“æ—¶é—´ä¸Šè¿›è¡Œå¹³å‡å¾—åˆ°ï¼Œæµ‹è¯•ç¯å¢ƒä½¿ç”¨[AWS p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/)å®ä¾‹ã€‚ NMS æ—¶é—´ (å¤§çº¦ 1 ms/img) ä¸åŒ…æ‹¬åœ¨å†…ã€‚
  å¤ç°å‘½ä»¤ `python val.py --data coco.yaml --img 640 --task speed --batch 1`
- **TTA** [æµ‹è¯•æ—¶æ•°æ®å¢å¼º](https://github.com/ultralytics/yolov5/issues/303) åŒ…æ‹¬åå°„å’Œå°ºåº¦å˜æ¢ã€‚
  å¤ç°å‘½ä»¤ `python val.py --data coco.yaml --img 1536 --iou 0.7 --augment`

# æ˜¾å¡è®­ç»ƒ

> [yolov5â€”â€”è®­ç»ƒç­–ç•¥](https://blog.csdn.net/CharmsLUO/article/details/123577851)

> [Train Custom Data Tutorial â­ Â· Issue #12 Â· ultralytics/yolov5 (github.com)](https://github.com/ultralytics/yolov5/issues/12)

```python
"""
Train a YOLOv5 model on a custom dataset.
Models and datasets download automatically from the latest YOLOv5 release.

Usage - Single-GPU training:
    $ python train.py --data coco128.yaml --weights yolov5s.pt --img 640  # from pretrained (recommended)
    $ python train.py --data coco128.yaml --weights '' --cfg yolov5s.yaml --img 640  # from scratch

Usage - Multi-GPU DDP training:
    $ python -m torch.distributed.run --nproc_per_node 4 --master_port 1 train.py --data coco128.yaml --weights yolov5s.pt --img 640 --device 0,1,2,3

Models:     https://github.com/ultralytics/yolov5/tree/master/models
Datasets:   https://github.com/ultralytics/yolov5/tree/master/data
Tutorial:   https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data
"""

def parse_opt(known=False):
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, default=ROOT / 'yolov5s.pt', help='initial weights path')
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')
    parser.add_argument('--epochs', type=int, default=100, help='total training epochs')
    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs, -1 for autobatch')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')
    parser.add_argument('--rect', action='store_true', help='rectangular training')
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
    parser.add_argument('--noval', action='store_true', help='only validate final epoch')
    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')
    parser.add_argument('--noplots', action='store_true', help='save no plot files')
    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='image --cache ram/disk')
    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    parser.add_argument('--project', default=ROOT / 'runs/train', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')
    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')
    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')
    parser.add_argument('--seed', type=int, default=0, help='Global training seed')
    parser.add_argument('--local_rank', type=int, default=-1, help='Automatic DDP Multi-GPU argument, do not modify')

    # Logger arguments
    parser.add_argument('--entity', default=None, help='Entity')
    parser.add_argument('--upload_dataset', nargs='?', const=True, default=False, help='Upload data, "val" option')
    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval')
    parser.add_argument('--artifact_alias', type=str, default='latest', help='Version of dataset artifact to use')

    return parser.parse_known_args()[0] if known else parser.parse_args()
```

> å­¦ä¹ ç‡çš„è°ƒæ•´åœ¨ `hyps`ä¸­è°ƒæ•´
>
> `initial learning rate (SGD=1E-2, Adam=1E-3)`

## å•æ˜¾å¡è®­ç»ƒ

> `SGD`

```sh
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-low.yaml  --optimizer SGD --cos-lr --device 0 --weights weights/yolov5n.pt --cfg models/yolov5n.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-low.yaml  --optimizer SGD --cos-lr --device 0 --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --device 0 --weights weights/yolov5m.pt --cfg models/yolov5m.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --device 0 --weights weights/yolov5l.pt --cfg models/yolov5l.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --device 0 --weights weights/yolov5x.pt --cfg models/yolov5x.yaml --data data/coco128.yaml
```

> `Adam` & `AdamW`

```sh
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-low-adam.yaml  --optimizer AdamW --cos-lr --device 0 --weights weights/yolov5n.pt --cfg models/yolov5n.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-low-adam.yaml  --optimizer AdamW --cos-lr --device 0 --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high-adam.yaml --optimizer AdamW --cos-lr --device 0 --weights weights/yolov5m.pt --cfg models/yolov5m.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high-adam.yaml --optimizer AdamW --cos-lr --device 0 --weights weights/yolov5l.pt --cfg models/yolov5l.yaml --data data/coco128.yaml
python train.py --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 --hyp data/hyps/hyp.scratch-high-adam.yaml --optimizer AdamW --cos-lr --device 0 --weights weights/yolov5x.pt --cfg models/yolov5x.yaml --data data/coco128.yaml
```

## å¤šæ˜¾å¡è®­ç»ƒ

- -m torch.distributed.launch pytorchå¯ç”¨å¤šçº¿ç¨‹
- --nproc_per_node=8      8å¼ æ˜¾å¡
- --device 0,1,2,3,4,5,6,7  8å¼ æ˜¾å¡åºå·

```sh
python -m torch.distributed.launch --nproc_per_node=8 train.py --device 0,1,2,3,4,5,6,7 --sync-bn --img 640 --batch-size -1 --workers 8--epochs 300 --save-period 10 \
--hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --cos-lr --weights weights/yolov5n.pt --cfg models/yolov5n.yaml --data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=8 train.py --device 0,1,2,3,4,5,6,7 --sync-bn --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 \
--hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --cos-lr --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=8 train.py --device 0,1,2,3,4,5,6,7 --sync-bn --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --weights weights/yolov5m.pt --cfg models/yolov5m.yaml --data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=8 train.py --device 0,1,2,3,4,5,6,7 --sync-bn --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --weights weights/yolov5l.pt --cfg models/yolov5l.yaml --data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=8 train.py --device 0,1,2,3,4,5,6,7 --sync-bn --img 640 --batch-size -1 --workers 8 --epochs 300 --save-period 10 \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --cos-lr --weights weights/yolov5x.pt --cfg models/yolov5x.yaml --data data/coco128.yaml
```

## **ä¸éœ€è¦åœ¨æ¨¡å‹é…ç½®ä¸­æ˜¾ç¤ºæ›´æ”¹ç±»åˆ«æ•°**

> ä¼šè‡ªåŠ¨å°†ncè°ƒæ•´ä¸ºæ•°æ®é›†çš„ç±»åˆ«æ•°é‡

```sh
> python train.py --img 640 --batch-size -1 --epochs 300 --hyp data/hyps/hyp.scratch-low.yaml  --optimizer SGD --cos-lr --device 0 --weights weights/yolov5n.pt --cfg models/yolov5n.yaml --data data/classes20.yaml
train: weights=weights/yolov5n.pt, cfg=models/yolov5n.yaml, data=data/classes20.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=True, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest
remote: Enumerating objects: 10, done.
remote: Counting objects: 100% (10/10), done.
remote: Compressing objects: 100% (10/10), done.
remote: Total 10 (delta 1), reused 4 (delta 0), pack-reused 0
Unpacking objects: 100% (10/10), 5.30 KiB | 246.00 KiB/s, done.
From https://github.com/ultralytics/yolov5
   b96f35c..b54fd0a  master     -> origin/master
 * [new branch]      dependabot/github_actions/actions/stale-8 -> origin/dependabot/github_actions/actions/stale-8
github:  YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.
YOLOv5  v7.0-128-gb96f35c Python-3.10.9 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)

hyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
ClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML
Comet: run 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet
TensorBoard: Start with 'tensorboard --logdir runs\train', view at http://localhost:6006/
Overriding model.yaml nc=80 with nc=20 		# è¿™é‡Œè‡ªåŠ¨è¦†ç›–äº†æ—§çš„ç±»åˆ«æ•°

                 from  n    params  module                                  arguments
  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]
  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]
  2                -1  1      4800  models.common.C3                        [32, 32, 1]
  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  4                -1  2     29184  models.common.C3                        [64, 64, 2]
  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  6                -1  3    156928  models.common.C3                        [128, 128, 3]
  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  8                -1  1    296448  models.common.C3                        [256, 256, 1]
  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]
 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]
 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]
 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]
 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 24      [17, 20, 23]  1     33825  models.yolo.Detect                      [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]
YOLOv5n summary: 214 layers, 1790977 parameters, 1790977 gradients, 4.3 GFLOPs
```

> è‡ªåŠ¨è°ƒæ•´ `nc` çš„ä»£ç åœ¨ `models/yolo.py`

```python
        if nc and nc != self.yaml['nc']: # ä½¿ç”¨data configä¸­çš„namesé•¿åº¦è¦†ç›–æ¨¡å‹é…ç½®æ–‡ä»¶ä¸­çš„ç±»åˆ«
            LOGGER.info(f"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}")
            self.yaml['nc'] = nc  # override yaml value
```

## è®­ç»ƒæ—¶å‡ºç°çš„é—®é¢˜

### è®­ç»ƒ `obj_loss` å¢å¤§ | reduce FPs | è§£å†³ç‰¹æ®Šåœºæ™¯æ¨¡å‹æ‹æ‘„æ—¥å¸¸ç›®æ ‡çš„FPæ•°é‡è¿‡å¤š

> [how to use Background images in training? Â· Issue #2844 Â· ultralytics/yolov5 (github.com)](https://github.com/ultralytics/yolov5/issues/2844)
>
> åœ¨å›¾ç‰‡è®­ç»ƒæ–‡ä»¶å¤¹ `images/train` ä¸­æ·»åŠ èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶ï¼Œæ¯”å¦‚cocoæˆ–è€…vocæ•°æ®é›†çš„ä¸€äº›ç…§ç‰‡
>
> ä¸éœ€è¦æ·»åŠ ç©ºç™½label txtæ–‡ä»¶ï¼Œæ·»åŠ äº†ä¹Ÿä¸ä¼šå‡ºé”™
>
> `(if no objects in image, no `*.txt` file is required).`
>
> [ç›®æ ‡æ£€æµ‹ï¼ˆé™ä½è¯¯æ£€æµ‹ç‡åŠå°ç›®æ ‡æ£€æµ‹ç³»åˆ—ç¬”è®°ï¼‰](https://blog.csdn.net/weixin_44836143/article/details/105952819)

```sh
train: Scanning D:\code\datasets\classes20\labels\train... 5266 images, 1000 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|
train: New cache created: D:\code\datasets\classes20\labels\train.cache
val: Scanning D:\code\datasets\classes20\labels\val... 586 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|
val: New cache created: D:\code\datasets\classes20\labels\val.cache
```

# export

```python
"""
Export a YOLOv5 PyTorch model to other formats. TensorFlow exports authored by https://github.com/zldrobit

Format                      | `export.py --include`         | Model
---                         | ---                           | ---
PyTorch                     | -                             | yolov5s.pt
TorchScript                 | `torchscript`                 | yolov5s.torchscript
ONNX                        | `onnx`                        | yolov5s.onnx
OpenVINO                    | `openvino`                    | yolov5s_openvino_model/
TensorRT                    | `engine`                      | yolov5s.engine
CoreML                      | `coreml`                      | yolov5s.mlmodel
TensorFlow SavedModel       | `saved_model`                 | yolov5s_saved_model/
TensorFlow GraphDef         | `pb`                          | yolov5s.pb
TensorFlow Lite             | `tflite`                      | yolov5s.tflite
TensorFlow Edge TPU         | `edgetpu`                     | yolov5s_edgetpu.tflite
TensorFlow.js               | `tfjs`                        | yolov5s_web_model/
PaddlePaddle                | `paddle`                      | yolov5s_paddle_model/

Requirements:
    $ pip install -r requirements.txt coremltools onnx onnxsim onnxruntime openvino-dev tensorflow-cpu  # CPU
    $ pip install -r requirements.txt coremltools onnx onnxsim onnxruntime-gpu openvino-dev tensorflow  # GPU

Usage:
    $ python export.py --weights yolov5s.pt --include torchscript onnx openvino engine coreml tflite ...

Inference:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle

TensorFlow.js:
    $ cd .. && git clone https://github.com/zldrobit/tfjs-yolov5-example.git && cd tfjs-yolov5-example
    $ npm install
    $ ln -s ../../yolov5/yolov5s_web_model public/yolov5s_web_model
    $ npm start
"""

def parse_opt(known=False):
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model.pt path(s)')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640, 640], help='image (h, w)')
    parser.add_argument('--batch-size', type=int, default=1, help='batch size')
    parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--half', action='store_true', help='FP16 half-precision export')
    parser.add_argument('--inplace', action='store_true', help='set YOLOv5 Detect() inplace=True')
    parser.add_argument('--keras', action='store_true', help='TF: use Keras')
    parser.add_argument('--optimize', action='store_true', help='TorchScript: optimize for mobile')
    parser.add_argument('--int8', action='store_true', help='CoreML/TF INT8 quantization')
    parser.add_argument('--dynamic', action='store_true', help='ONNX/TF/TensorRT: dynamic axes')
    parser.add_argument('--simplify', action='store_true', help='ONNX: simplify model')
    parser.add_argument('--opset', type=int, default=17, help='ONNX: opset version')
    parser.add_argument('--verbose', action='store_true', help='TensorRT: verbose log')
    parser.add_argument('--workspace', type=int, default=4, help='TensorRT: workspace size (GB)')
    parser.add_argument('--nms', action='store_true', help='TF: add NMS to model')
    parser.add_argument('--agnostic-nms', action='store_true', help='TF: add agnostic NMS to model')
    parser.add_argument('--topk-per-class', type=int, default=100, help='TF.js NMS: topk per class to keep')
    parser.add_argument('--topk-all', type=int, default=100, help='TF.js NMS: topk for all classes to keep')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='TF.js NMS: IoU threshold')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='TF.js NMS: confidence threshold')
    parser.add_argument(
        '--include',
        nargs='+',
        default=['torchscript'],
        help='torchscript, onnx, openvino, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle')
    opt = parser.parse_known_args()[0] if known else parser.parse_args()
    print_args(vars(opt))
    return opt
```

> å¯¼å‡ºè·¯å¾„å’Œæƒé‡è·¯å¾„ç›¸åŒ
>
> --include åé¢å†™æƒ³å¯¼å‡ºçš„æ ¼å¼

## torchscript

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include torchscript --device 0
python export.py --imgsz 640 --weights weights/yolov5s.pt --include torchscript --device cpu --optimize # --optimize not compatible with cuda devices, i.e. use --device cpu
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… 'onnxruntime-gpu' æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device 0

python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device 0 --half      			# --half only compatible with GPU export, i.e. use --device 0

python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device cpu --dynamic 			# --dynamic only compatible with cpu

python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device cpu --half --dynamic	# å¯¼å‡ºå¤±è´¥ --half not compatible with --dynamic
```

### opencvä½¿ç”¨çš„onnx

> https://github.com/ultralytics/ultralytics/tree/main/examples/YOLOv8-OpenCV-ONNX-Python

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device 0 --opset 12			# opsetå¿…é¡»ä¸º12

python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx --simplify --device 0 --half --opset 12	# opsetå¿…é¡»ä¸º12

# opencvä¸æ”¯æŒdynamic
```

## openvino

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include openvino --simplify --device cpu      # å¯ä»¥ç”¨simplifyçš„onnx
python export.py --imgsz 640 --weights weights/yolov5s.pt --include openvino --simplify --device 0 --half # openvinoæ”¯æŒhalf,ä½†æ˜¯è¦ä½¿ç”¨cpuå¯¼å‡ºonnxçš„halfä¼šæŠ¥é”™,æ‰€ä»¥è¦ä½¿ç”¨ --device 0, openvinoå¯¼å‡ºå’Œè®¾å¤‡æ— å…³,ä¸å—å½±å“,ä¸»è¦æ˜¯å¯¼å‡ºonnxçš„é—®é¢˜

python export.py --imgsz 640 --weights weights/yolov5s.pt --include openvino --simplify --device cpu --int8 # éœ€è¦å®‰è£…nncf
```

### é€šè¿‡openvinoçš„`mo`å‘½ä»¤å°†onnxè½¬æ¢ä¸ºopenvinoæ ¼å¼(æ”¯æŒ**fp16**)

> https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output.html

```sh
mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16

mo --input_model "onnx_path" --output_dir "output_path" --compress_to_fp16
```

#### ä»£ç æ–¹å¼

```python
from openvino.tools import mo
from openvino.runtime import serialize

onnx_path = "onnx_path"

# fp32 IR model
fp32_path = "fp32_path"
output_path = fp32_path + ".xml"
print(f"Export ONNX to OpenVINO FP32 IR to: {output_path}")
model = mo.convert_model(onnx_path)
serialize(model, output_path)

# fp16 IR model
fp16_path = "fp16_path"
output_path = fp16_path + ".xml"

print(f"Export ONNX to OpenVINO FP16 IR to: {output_path}")
model = mo.convert_model(onnx_path, compress_to_fp16=True)
serialize(model, output_path)
```

### export failure  0.9s: DLL load failed while importing ie_api

> https://blog.csdn.net/qq_26815239/article/details/123047840
>
> å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶ä¸”æ˜¯åœ¨Windowsç³»ç»Ÿä¸‹é€šè¿‡pipå®‰è£…çš„openvinoï¼Œé‚£ä¹ˆè¯¥é”™è¯¯çš„è§£å†³æ–¹æ¡ˆå¦‚ä¸‹ï¼š

1. è¿›å…¥ç›®å½• `your\env\site-packages\openvino\inference_engine`
2. æ‰“å¼€æ–‡ä»¶ `__init__.py`
3. 26è¡Œä¸‹æ·»åŠ ä¸€è¡Œ

```python
        if os.path.isdir(lib_path):
            # On Windows, with Python >= 3.8, DLLs are no longer imported from the PATH.
            if (3, 8) <= sys.version_info:
                os.add_dll_directory(os.path.abspath(lib_path))
                os.environ['PATH'] = os.path.abspath(lib_path) + ';' + os.environ['PATH']	# æ·»åŠ è¿™ä¸€è¡Œ
```

## tensorrt

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include engine --simplify --device 0 # å¯ä»¥ç”¨simplifyçš„onnx

python export.py --imgsz 640 --weights weights/yolov5s.pt --include engine --simplify --device 0 --half

python export.py --imgsz 640 --weights weights/yolov5s.pt --include engine --simplify --device 0 --dynamic --batch-size=16 	       # --dynamic model requires maximum --batch-size argument

python export.py --imgsz 640 --weights weights/yolov5s.pt --include engine --simplify --device 0 --half --dynamic --batch-size=16  # å¯¼å‡ºå¤±è´¥ --half not compatible with --dynamic, i.e. use either --half or --dynamic but not both
```

## onnx openvino tensorrt

```sh
python export.py --imgsz 640 --weights weights/yolov5s.pt --include onnx openvino engine --simplify --device 0 --half 
```

# detect

```python
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources:
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""

def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path or triton URL')
    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob/screen/0(webcam)')
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='(optional) dataset.yaml path')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='show results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    print_args(vars(opt))
    return opt
```

> sourceåé¢å¯ä»¥æ”¾å›¾ç‰‡ï¼Œè§†é¢‘æˆ–è€…æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¼šä¿å­˜åˆ°runs/detectç›®å½•ä¸‹é¢

`python detect.py --weights æƒé‡è·¯å¾„ --source å›¾ç‰‡orè§†é¢‘oræ–‡ä»¶å¤¹è·¯å¾„`



```python
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources:
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""
```

## torch

```sh
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.pt --source data/images/bus.jpg --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.pt --source ../datasets/coco128/images/train2017 --device 0
```

## torchscript

```sh
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.torchscript --source data/images/bus.jpg --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.torchscript --source ../datasets/coco128/images/train2017 --device 0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.onnx --source data/images/bus.jpg --device 0
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.onnx --source ../datasets/coco128/images/train2017 --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.onnx --half --source data/images/bus.jpg --device 0				# fp16æ¨¡å‹éœ€è¦ --half
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.onnx --half --source ../datasets/coco128/images/train2017 --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.onnx --half --source data/images/bus.jpg --device cpu				# gpuå¯¼å‡ºçš„fp16æ¨¡å‹å¯ä»¥ç”¨cpuæ¨ç†
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.onnx --half --source ../datasets/coco128/images/train2017 --device cpu

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.cpu.dynamic.onnx --source data/images/bus.jpg --device 0				# ä½¿ç”¨cpuå¯¼å‡ºçš„dynamicæ¨¡å‹å¯ä»¥ç”¨gpuæ¨ç†
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.cpu.dynamic.onnx --source ../datasets/coco128/images/train2017 --device 0
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ --device 0 ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s_openvino_model --source data/images/bus.jpg --device cpu

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s_openvino_model --source ../datasets/coco128/images/train2017 --device cpu
```

## tensorrt

```sh
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.engine --half --source data/images/bus.jpg --device 0					# fp32æ¨¡å‹ä¹Ÿèƒ½ç”¨ --half æ¨ç†
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.engine --half --source ../datasets/coco128/images/train2017 --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.engine --half --source data/images/bus.jpg --device 0
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp16.engine --half --source ../datasets/coco128/images/train2017 --device 0

python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp32.dynamic.engine --half --source data/images/bus.jpg --device 0		 # fp32æ¨¡å‹ä¹Ÿèƒ½ç”¨ --half æ¨ç†
python detect.py --imgsz 640 --save-txt --save-conf --save-crop --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.fp32.dynamic.engine --half --source ../datasets/coco128/images/train2017 --device 0
```

# val

```python
"""
Validate a trained YOLOv5 detection model on a detection dataset

Usage:
    $ python val.py --weights yolov5s.pt --data coco128.yaml --img 640

Usage - formats:
    $ python val.py --weights yolov5s.pt                 # PyTorch
                              yolov5s.torchscript        # TorchScript
                              yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                              yolov5s_openvino_model     # OpenVINO
                              yolov5s.engine             # TensorRT
                              yolov5s.mlmodel            # CoreML (macOS-only)
                              yolov5s_saved_model        # TensorFlow SavedModel
                              yolov5s.pb                 # TensorFlow GraphDef
                              yolov5s.tflite             # TensorFlow Lite
                              yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                              yolov5s_paddle_model       # PaddlePaddle
"""

def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path(s)')
    parser.add_argument('--batch-size', type=int, default=32, help='batch size')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf-thres', type=float, default=0.001, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.6, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=300, help='maximum detections per image')
    parser.add_argument('--task', default='val', help='train, val, test, speed or study')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--verbose', action='store_true', help='report mAP by class')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-json', action='store_true', help='save a COCO-JSON results file')
    parser.add_argument('--project', default=ROOT / 'runs/val', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    opt = parser.parse_args()
    opt.data = check_yaml(opt.data)  # check YAML
    opt.save_json |= opt.data.endswith('coco.yaml')
    opt.save_txt |= opt.save_hybrid
    print_args(vars(opt))
    return opt
```

## default confidence threshold = 0.001

> [mAP bug at higher --conf Â· Issue #1466 Â· ultralytics/yolov5](https://github.com/ultralytics/yolov5/issues/1466)
>
> [Why does the confidence threshold of 0.001 in val.py result in good results? Â· Issue #11745 Â· ultralytics/yolov5](https://github.com/ultralytics/yolov5/issues/11745)

## éªŒè¯æ¨¡å‹åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„æ•ˆæœ ç²¾åº¦0.995

> https://www.jianshu.com/p/cfb01add61bd#1684051613808
>
> https://github.com/ultralytics/yolov5/issues/5508
>
> https://github.com/ultralytics/yolov5/issues/1563
>
> https://github.com/ultralytics/yolov5/pull/1646
>
>  `--save-hybrid` ä¼šåˆå¹¶å·²çŸ¥çš„labelsï¼Œå¯¼è‡´å¾—åˆ†å¾ˆé«˜

## torch

```sh
python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.pt --device 0
```

## torchscript

```sh
python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.torchscript --device 0
```

## onnx

> æ³¨æ„:
>
> `onnxruntime` å’Œ `onnxruntime-gpu` ä¸è¦åŒæ—¶å®‰è£…ï¼Œå¦åˆ™ä½¿ç”¨ `gpu` æ¨ç†æ—¶é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œå¦‚æœåŒæ—¶å®‰è£…äº†2ä¸ªåŒ…ï¼Œè¦å…¨éƒ¨å¸è½½ï¼Œå†å®‰è£… `onnxruntime-gpu` æ‰èƒ½ä½¿ç”¨gpuæ¨ç†ï¼Œå¦åˆ™gpué€Ÿåº¦ä¼šå¾ˆæ…¢

```sh
python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.onnx --device 0

python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.onnx --device 0 --dnn
```

## openvino

> æ³¨æ„ï¼šopenvinoæ²¡æ³•ä½¿ç”¨cudaï¼Œä½†æ˜¯ä½¿ç”¨ --device 0 ä¼šæé«˜æ¨ç†é€Ÿåº¦

```sh
python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s_openvino_model --device cpu
```

## tensorrt

```sh
python val.py --imgsz 640 --save-txt --save-conf --save-json --conf-thres 0.25 --iou-thres 0.6 --data data/coco128.yaml --weights weights/yolov5s.engine --device 0
```

