# Êï∞ÊçÆÈõÜ

> ÂÖàË¶ÅÊääÊï∞ÊçÆÈõÜÊîæÂÖ•dataset‰∏≠Ôºå‰øÆÊîπdata/ÁõÆÂΩï‰∏ãÁöÑyamlÔºåË∞ÉÊï¥‰∏∫Ëá™Â∑±ÁöÑÊï∞ÊçÆÈõÜÔºåÈúÄË¶ÅË∞ÉÊï¥Ë∑ØÂæÑÔºåÂàÜÁ±ªÊï∞ÔºåÊ†áÁ≠æÂêç

> yoloÊï∞ÊçÆÈõÜÊ†ºÂºè(yolov5ÁöÑcoco128ÂíåÈúπÈõ≥ÂêßÂï¶WzÁöÑyolo3‰∏∫‰æã)
>
> txtÂÜÖÂÆπÔºåÊØè‰∏ÄË°åÈÉΩÊòØ `3 0.933536 0.486124 0.030408 0.154487`
>
> ÊòØ label ‰∏≠ÂøÉÊ®™ÂùêÊ†á‰∏éÂõæÂÉèÂÆΩÂ∫¶ÊØîÂÄº ‰∏≠ÂøÉÁ∫µÂùêÊ†á‰∏éÂõæÂÉèÈ´òÂ∫¶ÊØîÂÄº bboxÂÆΩÂ∫¶‰∏éÂõæÂÉèÂÆΩÂ∫¶ÊØîÂÄº bboxÈ´òÂ∫¶‰∏éÂõæÂÉèÂÆΩÈ´òÊØîÂÄº

```
#-------------------------------------------#
# 	yolov5ÁöÑcoco128Ê†ºÂºè
# 	ÈúÄË¶ÅÂú®~data/coco128.yaml‰∏≠‰øÆÊîπÂ¶Ç‰∏ã‰ø°ÊÅØ
# 	nc: 10  # ÂàÜÁ±ªÊï∞Ë¶ÅÂíådataset‰∏≠‰∏ÄËá¥
# 	names: ["aeroplane", "bicycle", "bird", "boat", "bottle": 5] # ÂàÜÁ±ªÂêçÁß∞
#-------------------------------------------#
datasets
‚îú‚îÄ‚îÄ coco128
	‚îú‚îÄ‚îÄ images
    ‚îÇ	‚îú‚îÄ‚îÄ train2017	ËÆ≠ÁªÉÂõæÁâá
    ‚îÇ	‚îî‚îÄ‚îÄ val2017		È™åËØÅÂõæÁâá
	‚îî‚îÄ‚îÄ labels
    	‚îú‚îÄ‚îÄ train2017	ËÆ≠ÁªÉÊ†áÁ≠ætxt
    	‚îî‚îÄ‚îÄ val2017		È™åËØÅÊ†áÁ≠ætxt


#-------------------------------------------#
#	ÈúπÈõ≥ÂêßÂï¶WzÁöÑyolo3
#-------------------------------------------#
data
‚îú‚îÄ‚îÄ pascal_voc_classes.json		Â≠òÊîæÁ±ªÂà´‰ø°ÊÅØ {"aeroplane": 1, "bicycle": 2, "bird": 3, "boat": 4, "bottle": 5}
‚îú‚îÄ‚îÄ train
‚îÇ	‚îú‚îÄ‚îÄ images		ËÆ≠ÁªÉÂõæÁâá
‚îÇ	‚îî‚îÄ‚îÄ labels		ËÆ≠ÁªÉÊ†áÁ≠ætxt
‚îî‚îÄ‚îÄ val
	‚îú‚îÄ‚îÄ images		È™åËØÅÂõæÁâá
	‚îî‚îÄ‚îÄ labels		È™åËØÅÂõæÁâátxt
```

> data/class10.yaml

```yaml
# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics
# Example usage: python train.py --data coco128.yaml
# parent
# ‚îú‚îÄ‚îÄ yolov5
# ‚îî‚îÄ‚îÄ datasets
#     ‚îî‚îÄ‚îÄ yourname
#         ‚îî‚îÄ‚îÄ images/
#             ‚îî‚îÄ‚îÄ train2017/  Â≠òÊîæËÆ≠ÁªÉÂõæÁâá
#             ‚îî‚îÄ‚îÄ val2017/    Â≠òÊîæÈ™åËØÅÂõæÁâá
#         ‚îî‚îÄ‚îÄ labels/
#             ‚îî‚îÄ‚îÄ train2017/  Â≠òÊîæËÆ≠ÁªÉÊ†áÁ≠æ  class x_center y_center width height
#             ‚îî‚îÄ‚îÄ val2017/    Â≠òÊîæÈ™åËØÅÊ†áÁ≠æ


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ./datasets/coco128  # dataset root dir
train: images/train2017  # train images (relative to 'path') 128 images
val: images/val2017  # val images (relative to 'path') 128 images
test:  # test images (optional)

# Classes
nc: 10  # ÂàÜÁ±ªÊï∞Ë¶ÅÂíådataset‰∏≠‰∏ÄËá¥
names: [
  "breakglue",
  "dot",
  "double",
  "gap",
  "mulglue",
  "noglue",
  "pit",
  "press",
  "reverse",
  "scratch"
]  # class names
```

# Ê®°Âûã

> ÁÑ∂ÂêéÂú®`models/yolov5*.yaml`‰∏≠ËÆæÁΩÆÁõ∏ÂêåÁöÑÂàÜÁ±ªÊï∞

```yaml
# Parameters
nc: 10  # Ë∞ÉÊï¥‰∏∫Ëá™Â∑±ÁöÑÂàÜÁ±ªÊï∞
```

# ‰∏ãËΩΩÊùÉÈáç

> Â∞Ü‰∏ãËΩΩÂ•ΩÁöÑÊùÉÈáçÊîæÂà∞`weights/`Êñá‰ª∂‰∏ã‰∏ã

# Pretrained Checkpoints

| Model                                                        | size (pixels) | mAPval 0.5:0.95 | mAPval 0.5    | Speed CPU b1 (ms) | Speed V100 b1 (ms) | Speed V100 b32 (ms) | params (M) | FLOPs @640 (B) |
| ------------------------------------------------------------ | ------------- | --------------- | ------------- | ----------------- | ------------------ | ------------------- | ---------- | -------------- |
| [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt) | 640           | 28.0            | 45.7          | **45**            | **6.3**            | **0.6**             | **1.9**    | **4.5**        |
| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt) | 640           | 37.4            | 56.8          | 98                | 6.4                | 0.9                 | 7.2        | 16.5           |
| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m.pt) | 640           | 45.4            | 64.1          | 224               | 8.2                | 1.7                 | 21.2       | 49.0           |
| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l.pt) | 640           | 49.0            | 67.3          | 430               | 10.1               | 2.7                 | 46.5       | 109.1          |
| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x.pt) | 640           | 50.7            | 68.9          | 766               | 12.1               | 4.8                 | 86.7       | 205.7          |
|                                                              |               |                 |               |                   |                    |                     |            |                |
| [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n6.pt) | 1280          | 36.0            | 54.4          | 153               | 8.1                | 2.1                 | 3.2        | 4.6            |
| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s6.pt) | 1280          | 44.8            | 63.7          | 385               | 8.2                | 3.6                 | 12.6       | 16.8           |
| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m6.pt) | 1280          | 51.3            | 69.3          | 887               | 11.1               | 6.8                 | 35.7       | 50.0           |
| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5l6.pt) | 1280          | 53.7            | 71.3          | 1784              | 15.8               | 10.5                | 76.8       | 111.4          |
| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x6.pt) + [TTA](https://github.com/ultralytics/yolov5/issues/303) | 1280 1536     | 55.0 **55.8**   | 72.7 **72.7** | 3136 -            | 26.2 -             | 19.4 -              | 140.7 -    | 209.8 -        |

<details open="">
  <summary>Table Notes (click to expand)</summary>
<ul dir="auto">
<li>All checkpoints are trained to 300 epochs with default settings. Nano and Small models use <a href="https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml">hyp.scratch-low.yaml</a> hyps, all others use <a href="https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-high.yaml">hyp.scratch-high.yaml</a>.</li>
<li><strong>mAP<sup>val</sup></strong> values are for single-model single-scale on <a href="http://cocodataset.org" rel="nofollow">COCO val2017</a> dataset.<br>Reproduce by <code>python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65</code></li>
<li><strong>Speed</strong> averaged over COCO val images using a <a href="https://aws.amazon.com/ec2/instance-types/p3/" rel="nofollow">AWS p3.2xlarge</a> instance. NMS times (~1 ms/img) not included.<br>Reproduce by <code>python val.py --data coco.yaml --img 640 --task speed --batch 1</code></li>
<li><strong>TTA</strong> <a href="https://github.com/ultralytics/yolov5/issues/303" data-hovercard-type="issue" data-hovercard-url="/ultralytics/yolov5/issues/303/hovercard">Test Time Augmentation</a> includes reflection and scale augmentations.<br>Reproduce by <code>python val.py --data coco.yaml --img 1536 --iou 0.7 --augment</code></li>
</ul>
</details>

# ÊòæÂç°ËÆ≠ÁªÉ

```python
"""
Train a YOLOv5 model on a custom dataset.
Models and datasets download automatically from the latest YOLOv5 release.

Usage - Single-GPU training:
    $ python train.py --data coco128.yaml --weights yolov5s.pt --img 640  # from pretrained (recommended)
    $ python train.py --data coco128.yaml --weights '' --cfg yolov5s.yaml --img 640  # from scratch

Usage - Multi-GPU DDP training:
    $ python -m torch.distributed.run --nproc_per_node 4 --master_port 1 train.py --data coco128.yaml --weights yolov5s.pt --img 640 --device 0,1,2,3

Models:     https://github.com/ultralytics/yolov5/tree/master/models
Datasets:   https://github.com/ultralytics/yolov5/tree/master/data
Tutorial:   https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data
"""


def parse_opt(known=False):
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, default=ROOT / 'yolov5s.pt', help='initial weights path')
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')
    parser.add_argument('--epochs', type=int, default=300, help='total training epochs')
    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs, -1 for autobatch')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')
    parser.add_argument('--rect', action='store_true', help='rectangular training')
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
    parser.add_argument('--noval', action='store_true', help='only validate final epoch')
    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')
    parser.add_argument('--noplots', action='store_true', help='save no plot files')
    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='--cache images in "ram" (default) or "disk"')
    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    parser.add_argument('--project', default=ROOT / 'runs/train', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')
    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')
    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')
    parser.add_argument('--seed', type=int, default=0, help='Global training seed')
    parser.add_argument('--local_rank', type=int, default=-1, help='Automatic DDP Multi-GPU argument, do not modify')

    # Logger arguments
    parser.add_argument('--entity', default=None, help='Entity')
    parser.add_argument('--upload_dataset', nargs='?', const=True, default=False, help='Upload data, "val" option')
    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval')
    parser.add_argument('--artifact_alias', type=str, default='latest', help='Version of dataset artifact to use')

    return parser.parse_known_args()[0] if known else parser.parse_args()
```


## ÂçïÊòæÂç°ËÆ≠ÁªÉ

> ex:

```sh
python train.py --img 640 --batch-size -1 --epochs 300 --device 0 --cos-lr --hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --weights weights/yolov5n.pt --cfg models/yolov5n.yaml --data data/coco128.yaml

python train.py --img 640 --batch-size -1 --epochs 300 --device 0 --cos-lr --hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/coco128.yaml

python train.py --img 640 --batch-size -1 --epochs 300 --device 0 --cos-lr --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5m.pt --cfg models/yolov5m.yaml --data data/coco128.yaml

python train.py --img 640 --batch-size -1 --epochs 300 --device 0 --cos-lr --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5l.pt --cfg models/yolov5l.yaml --data data/coco128.yaml

python train.py --img 640 --batch-size -1 --epochs 300 --device 0 --cos-lr --hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5x.pt --cfg models/yolov5x.yaml --data data/coco128.yaml
```

## Â§öÊòæÂç°ËÆ≠ÁªÉ

- -m torch.distributed.launch pytorchÂêØÁî®Â§öÁ∫øÁ®ã
- --nproc_per_node=2 2Âº†ÊòæÂç°
- --device 0,1     2Âº†ÊòæÂç°Â∫èÂè∑

```sh
python -m torch.distributed.launch --nproc_per_node=2 train.py --img 640 --batch-size -1 --epochs 300 --device 0,1 --cos-lr \
--hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --weights weights/yolov5n.pt --cfg models/yolov5n.yaml \
--data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=2 train.py --img 640 --batch-size -1 --epochs 300 --device 0,1 --cos-lr \
--hyp data/hyps/hyp.scratch-low.yaml --optimizer SGD --weights weights/yolov5s.pt --cfg models/yolov5s.yaml \
--data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=2 train.py --img 640 --batch-size -1 --epochs 300 --device 0,1 --cos-lr \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5m.pt --cfg models/yolov5m.yaml \
--data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=2 train.py --img 640 --batch-size -1 --epochs 300 --device 0,1 --cos-lr \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5l.pt --cfg models/yolov5l.yaml \
--data data/coco128.yaml

python -m torch.distributed.launch --nproc_per_node=2 train.py --img 640 --batch-size -1 --epochs 300 --device 0,1 --cos-lr \
--hyp data/hyps/hyp.scratch-high.yaml --optimizer SGD --weights weights/yolov5x.pt --cfg models/yolov5x.yaml \
--data data/coco128.yaml
```

# export

```python
"""
Export a YOLOv5 PyTorch model to other formats. TensorFlow exports authored by https://github.com/zldrobit

Format                      | `export.py --include`         | Model
---                         | ---                           | ---
PyTorch                     | -                             | yolov5s.pt
TorchScript                 | `torchscript`                 | yolov5s.torchscript
ONNX                        | `onnx`                        | yolov5s.onnx
OpenVINO                    | `openvino`                    | yolov5s_openvino_model/
TensorRT                    | `engine`                      | yolov5s.engine
CoreML                      | `coreml`                      | yolov5s.mlmodel
TensorFlow SavedModel       | `saved_model`                 | yolov5s_saved_model/
TensorFlow GraphDef         | `pb`                          | yolov5s.pb
TensorFlow Lite             | `tflite`                      | yolov5s.tflite
TensorFlow Edge TPU         | `edgetpu`                     | yolov5s_edgetpu.tflite
TensorFlow.js               | `tfjs`                        | yolov5s_web_model/
PaddlePaddle                | `paddle`                      | yolov5s_paddle_model/

Requirements:
    $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime openvino-dev tensorflow-cpu  # CPU
    $ pip install -r requirements.txt coremltools onnx onnx-simplifier onnxruntime-gpu openvino-dev tensorflow  # GPU

Usage:
    $ python export.py --weights yolov5s.pt --include torchscript onnx openvino engine coreml tflite ...

Inference:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s.xml                # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""


def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model.pt path(s)')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640, 640], help='image (h, w)')
    parser.add_argument('--batch-size', type=int, default=1, help='batch size')
    parser.add_argument('--device', default='cpu', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--half', action='store_true', help='FP16 half-precision export')
    parser.add_argument('--inplace', action='store_true', help='set YOLOv5 Detect() inplace=True')
    parser.add_argument('--keras', action='store_true', help='TF: use Keras')
    parser.add_argument('--optimize', action='store_true', help='TorchScript: optimize for mobile')
    parser.add_argument('--int8', action='store_true', help='CoreML/TF INT8 quantization')
    parser.add_argument('--dynamic', action='store_true', help='ONNX/TF/TensorRT: dynamic axes')
    parser.add_argument('--simplify', action='store_true', help='ONNX: simplify model')
    parser.add_argument('--opset', type=int, default=12, help='ONNX: opset version')
    parser.add_argument('--verbose', action='store_true', help='TensorRT: verbose log')
    parser.add_argument('--workspace', type=int, default=4, help='TensorRT: workspace size (GB)')
    parser.add_argument('--nms', action='store_true', help='TF: add NMS to model')
    parser.add_argument('--agnostic-nms', action='store_true', help='TF: add agnostic NMS to model')
    parser.add_argument('--topk-per-class', type=int, default=100, help='TF.js NMS: topk per class to keep')
    parser.add_argument('--topk-all', type=int, default=100, help='TF.js NMS: topk for all classes to keep')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='TF.js NMS: IoU threshold')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='TF.js NMS: confidence threshold')
    parser.add_argument(
        '--include',
        nargs='+',
        default=['torchscript'],
        help='torchscript, onnx, openvino, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle')
    opt = parser.parse_args()
    print_args(vars(opt))
    return opt
```

> ÂØºÂá∫Ë∑ØÂæÑÂíåÊùÉÈáçË∑ØÂæÑÁõ∏Âêå
>
> --include ÂêéÈù¢ÂÜôÊÉ≥ÂØºÂá∫ÁöÑÊ†ºÂºè

## torchscript

```python
python export.py --weights weights/yolov5s.pt --include torchscript --device 0
```

## onnx

```python
python export.py --weights weights/yolov5s.pt --include onnx --simplify
```

## openvino

```python
python export.py --weights weights/yolov5s.pt --include openvino
```

### export failure  0.9s: DLL load failed while importing ie_api

> https://blog.csdn.net/qq_26815239/article/details/123047840
>
> Â¶ÇÊûú‰Ω†‰ΩøÁî®ÁöÑÊòØ Python 3.8 ÊàñÊõ¥È´òÁâàÊú¨ÔºåÂπ∂‰∏îÊòØÂú®WindowsÁ≥ªÁªü‰∏ãÈÄöËøápipÂÆâË£ÖÁöÑopenvinoÔºåÈÇ£‰πàËØ•ÈîôËØØÁöÑËß£ÂÜ≥ÊñπÊ°àÂ¶Ç‰∏ãÔºö

1. ËøõÂÖ•ÁõÆÂΩï `your\env\site-packages\openvino\inference_engine`
2. ÊâìÂºÄÊñá‰ª∂ `__init__.py`
3. 26Ë°å‰∏ãÊ∑ªÂä†‰∏ÄË°å

```python
        if os.path.isdir(lib_path):
            # On Windows, with Python >= 3.8, DLLs are no longer imported from the PATH.
            if (3, 8) <= sys.version_info:
                os.add_dll_directory(os.path.abspath(lib_path))
                os.environ['PATH'] = os.path.abspath(lib_path) + ';' + os.environ['PATH']	# Ê∑ªÂä†Ëøô‰∏ÄË°å
```

## tensorrt

```python
python export.py --weights weights/yolov5s.pt --include engine --device 0 --half
```

# detect

```python
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources:
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     path/                           # directory
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s.xml                # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""


def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path or triton URL')
    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob/screen/0(webcam)')
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='(optional) dataset.yaml path')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='show results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    print_args(vars(opt))
    return opt
```

> sourceÂêéÈù¢ÂèØ‰ª•ÊîæÂõæÁâáÔºåËßÜÈ¢ëÊàñËÄÖÊñá‰ª∂Â§πË∑ØÂæÑÔºå‰ºö‰øùÂ≠òÂà∞runs/detectÁõÆÂΩï‰∏ãÈù¢

`python detect.py --weights ÊùÉÈáçË∑ØÂæÑ --source ÂõæÁâáorËßÜÈ¢ëorÊñá‰ª∂Â§πË∑ØÂæÑ`



```python
# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources:
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""
```

## torch

```python
python detect.py --imgsz 640 --device 0 --weights weights/yolov5s.pt --data data/coco128.yaml --source data/images/bus.jpg

python detect.py --imgsz 640 --device 0 --weights weights/yolov5s.pt --data data/coco128.yaml --source ../datasets/coco128/images/train2017
```

## torchscript

```python
python detect.py --imgsz 640 --device 0 --weights weights/yolov5s.torchscript --data data/coco128.yaml --source data/images/bus.jpg

python detect.py --imgsz 640 --device 0 --weights weights/yolov5s.torchscript --data data/coco128.yaml --source ../datasets/coco128/images/train2017
```

## onnx

> Ê≥®ÊÑèÔºöpytorch1.12ÂØºÂá∫ÁöÑonnxÊ≤°Ê≥ïË¢´dnnËØªÂèñÔºå1.11ÂèØ‰ª• [reference](https://github.com/ultralytics/yolov5/issues/8439)

```python
python detect.py --imgsz 640 --device 0  --weights weights/yolov5s.onnx --data data/coco128.yaml --source data/images/bus.jpg
python detect.py --imgsz 640 --weights weights/yolov5s.onnx --data data/coco128.yaml --dnn --source data/images/bus.jpg

python detect.py --imgsz 640 --device 0  --weights weights/yolov5s.onnx --data data/coco128.yaml --source ../datasets/coco128/images/train2017
python detect.py --imgsz 640 --weights weights/yolov5s.onnx --data data/coco128.yaml --dnn --source ../datasets/coco128/images/train2017
```

## openvino

```python
python detect.py --imgsz 640 --weights weights/yolov5s_openvino_model --data data/coco128.yaml --source data/images/bus.jpg

python detect.py --imgsz 640 --weights weights/yolov5s_openvino_model --data data/coco128.yaml --source ../datasets/coco128/images/train2017
```

## tensorrt

```python
python detect.py --imgsz 640 --device 0 --half --weights weights/yolov5s.engine --data data/coco128.yaml --source data/images/bus.jpg

python detect.py --imgsz 640 --device 0 --half --weights weights/yolov5s.engine --data data/coco128.yaml --source ../datasets/coco128/images/train2017
```

# val

```python
def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path(s)')
    parser.add_argument('--batch-size', type=int, default=32, help='batch size')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf-thres', type=float, default=0.001, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.6, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=300, help='maximum detections per image')
    parser.add_argument('--task', default='val', help='train, val, test, speed or study')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--verbose', action='store_true', help='report mAP by class')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-json', action='store_true', help='save a COCO-JSON results file')
    parser.add_argument('--project', default=ROOT / 'runs/val', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    opt = parser.parse_args()
    opt.data = check_yaml(opt.data)  # check YAML
    opt.save_json |= opt.data.endswith('coco.yaml')
    opt.save_txt |= opt.save_hybrid
    print_args(vars(opt))
    return opt
```

## torch

```python
python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 --device 0 \
--batch-size 32 --weights weights/yolov5s.pt --data data/coco128.yaml
```

## torchscript

```python
python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 --device 0 \
--batch-size 32 --weights weights/yolov5s.torchscript --data data/coco128.yaml
```

## onnx

```python
python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 \
--batch-size 32 --weights weights/yolov5s.onnx --data data/coco128.yaml

python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 \
--batch-size 32 --dnn --weights weights/yolov5s.onnx --data data/coco128.yaml
```

## openvino

```python
python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 \
--batch-size 32 --weights weights/yolov5s_openvino_model --data data/coco128.yaml
```

## tensorrt

```python
python val.py --imgsz 640 --save-txt --save-hybrid --save-conf --save-json --conf-thres 0.25 --iou-thres 0.45 --device 0 --half \
--batch-size 32 --weights weights/yolov5s.engine --data data/coco128.yaml
```

